# Database URL -- used in Prisma 
# https://pris.ly/d/prisma-schema#accessing-environment-variables-from-the-schema
# 
DATABASE_URL="postgresql://secure-ai-tools-dev:SecureAIToolsFTW!@127.0.0.1:5432/secure-ai-tools-dev-db"

# Path for local-object-storage
LOCAL_OBJECT_STORAGE_DIR="/Users/<USER>/.SecureAI.tools/local-objects"

# Winston logging level
LOG_LEVEL="debug"

# Inference server
INFERENCE_SERVER="http://localhost:28664/"

# Chroma server
VECTOR_DB_SERVER="http://localhost:8000"

# Document indexing and retrieval configs
# Please check your embeddings model limits and increase it if it's allowed, for OpenAI text-embedding-3-large model, the limit is 3000 tokens so this could be set up to 2800
DOCS_INDEXING_CHUNK_SIZE=1000
DOCS_INDEXING_CHUNK_OVERLAP=200
DOCS_RETRIEVAL_K=2

# Model provider configs
# Configure external model providers here. Needs to be serialized JSON of ModelProviderConfig[]
# https://github.com/SecureAI-Tools/SecureAI-Tools/blob/main/packages/core/src/types/model-provider-config.ts
MODEL_PROVIDER_CONFIGS='[{"type":"OPENAI","apiBaseUrl":"https://api.openai.com/v1","apiKey":"...","embeddingsModel":"text-embedding-3-large"}]'

# AMQP Server (RabbitMQ) info
AMQP_SERVER_URL="amqp://localhost:5672"
AMQP_DOCS_INDEXING_QUEUE_NAME="documents-indexing-queue"
