version: "3.8"

services:
  web:
    image: public.ecr.aws/d8f2p0h3/secure-ai-tools:latest
    platform: linux/amd64
    volumes:
      - ./web:/app/volume
    env_file:
      - .env
    environment:
      - INFERENCE_SERVER=http://inference:11434/
      - VECTOR_DB_SERVER=http://vector-db:8000
    ports:
      - 28669:28669
    command: sh -c "cd /app && sh tools/db-migrate-and-seed.sh ${DATABASE_FILE} && node server.js"
    depends_on:
      - inference
      - vector-db

  vector-db:
    image: chromadb/chroma:latest
    volumes:
      # Default configuration for persist_directory is "/chroma/chroma/"
      - ./vector-db:/chroma/chroma/

  inference:
    image: ollama/ollama:latest
    volumes:
      - ./inference:/root/.ollama
    #
    # Uncomment for Linux machines with Nvidia GPUs
    # Based on https://docs.docker.com/compose/gpu-support/
    # Requires Nvidia container toolkit: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#installation
    #
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 'all'
    #           capabilities: [gpu]
